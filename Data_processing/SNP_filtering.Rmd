---
title: "SNP filtering using vcfR"
author: "D. G. Gannon"
date: "September 2020"
output: pdf_document
bibliography: /Users/dusty/Documents/zotero_library.bib
header-includes:
  \usepackage{setspace}
  \onehalfspacing
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

  require(vcfR)
  require(stringr)

```

  Previous quality filters up to this point include:  
  
  1) Demultiplexing phase: Removing reads for which Phred score falls below 10 in a 15% sliding window (\texttt{process\_radtags} program)
  
  2) Demultiplexing phase: Removing reads with an uncalled base (\texttt{process\_radtags} program)
  
  3) Catalog phase: Discard alignments with Phred scores < 20 (i.e. only keep alignments for which $\text{Pr}(\text{Incorrect alignment} < 0.01)$; \texttt{gstacks} program)
  
  4) Genotyping: Loci must be present in at least 85% of individuals per population and all four populations (meadow complexes) sampled
  
  5) Locus filters: vcf file is filtered to include only bi-allelic loci using \texttt{vcftools}.
  
  

```{bash, eval=FALSE}
  vcftools --vcf ./AQFO_snps_r80.vcf --min-alleles 2 --max-alleles 2 --recode --recode-INFO-all \
  --out ./AQFO_snps_r80_bi
```


\subsubsection{Filtering SNPs based on depth}

  Repetitive or similar regions in the genome may result in reads that come from different locations in the genome getting erroneously merged and aligned. This can result in exceptionally deep coverage on certain loci and could result in spurious SNP calls. We use the effective per-sample coverage reported from the \texttt{gstacks} of \texttt{Stacks v2} to create a depth threshold. We set the depth threshold, $d^*$, as
  
$$
0.0001 = 1-P(d_{ij} \le d_i^*\ |\ \lambda_i),
$$
where, $\lambda_i$ is the reported effective coverage for sample $i$ from the \texttt{gstacks} program, $d_{ij}$ is the depth at locus $j$ for sample $i$, and 
$P(\cdot)$ is computed based on the Poisson PMF with rate parameter $\lambda_i$.

  We do not remove SNPs with low depth because the model that calls genotypes in \texttt{Stacks v2} avoids calling genotypes when uncertainty in the call is high [@maruki2017]. 
  
```{r, message=FALSE, include=FALSE}

  col.vcf <- read.vcfR("~/Documents/Columbine/Data/GBS_Data/AQFO_snps_r80_bi.vcf")

  coverage <- read.table("~/Documents/Columbine/Data/GBS_Data/coverage_per_sample.txt", header = T, 
                         sep = "\t", as.is = T)

```


```{r depth filters}

  dp <- extract.gt(col.vcf, element = "DP", as.numeric = T)

# Replace exceedingly high read depths with NAs in depth matrix
  quants <- qpois(0.0001, lambda = coverage$mean_cov_ns, lower.tail = F)
  
  dp2 <- sweep(dp, MARGIN = 2, STATS = quants, FUN = "-")
  
  dp[dp2 > 0] <- NA

```



```{r missingness filter}

#Filter out the snps with lots of missing data

  miss_snp <- apply(dp, MARGIN = 1, function(x){ sum( is.na(x) ) } )
  miss_snp <- miss_snp / ncol(dp)
  col.vcf.good <- col.vcf[miss_snp <= 0.05, ]
  
  

# get a list of snp id's to remove
  
  site2rm <- col.vcf@fix[miss_snp > 0.05, 3]
  
 #  write.table(site2rm, "~/Documents/Columbine/Data/GBS_Data/exclude_sites.txt", 
 #              quote = F, sep = "\t",
 #            row.names = F, col.names = F)

  
```

$~$

Using the list of SNPs to exclude, we use vcftools to rewrite the vcf file with only the loci we wish to keep.

$~$
 
 
```{bash, eval=FALSE}
  vcftools --vcf ./AQFO_snps_r80_bi.vcf --exclude ./exclude_sites.txt --recode --recode-INFO-all \ 
  --out ./AQFO_snps_postfilt
```


$~$

```{r, include=FALSE}
  
  col.vcf.good <- read.vcfR("~/Documents/Columbine/Data/GBS_Data/AQFO_snps_postfilt.vcf")
  
```



```{r}

  dp.good <- extract.gt(col.vcf.good, element = "DP", as.numeric = T)
  col.gt <- extract.gt(col.vcf.good, element = "GT")
  
  heatmap.bp(dp.good, rlabels = F)

```
**Figure 1** Heatmap of sequencing depth across the filtered dataset.


 With this vcf file containing `r round(sum(is.na(col.gt))/(nrow(col.gt)*ncol(col.gt)),4)*100` percent missing information, `r dim(dp.good)[1]` SNPs and 192 individual plants, we impute the missing genotypes using \texttt{BEAGLE} [@browning2016].
 
$~$

\subsubsection{Filtering SNPs based on exon annotations}

Read in the annotations file from the *A. coerulea* genome and store as a dataframe.

```{r annotations}

# read in the imputed vcf
  col.vcf.good <- read.vcfR(file = "~/Documents/Columbine/Data/GBS_Data/AQFO_snsp_impute.vcf")
  ann <- read.table("~/Documents/Columbine/Data/GBS_Data/Acoerulea_322_v3.1.gene_exons.gff3",
                    header = F, sep = "\t", as.is = T)[,c(1,3:5,7)]

# name columns
  names(ann) <- c("Chrom", "annot", "start", "stop", "strand")
  
# structure of the data
  head(ann)
  
```

```{r annotate, eval=FALSE}
# annotate snps
  snps <- as.data.frame(col.vcf.good@fix)
  snps$POS <- as.numeric(snps$POS)
  snps$strand <- str_split(snps$ID, ":", simplify = T)[,3]
  snps$SOFA <- NA
  
  for(i in 1:nrow(snps)){
    annots_i <- which((ann$Chrom == snps$CHROM[i]) &
           (ann$start < snps$POS[i]) &
            (ann$stop > snps$POS[i]) &
            ann$strand == snps$strand[i])
    if(length(annots_i) == 1){
      snps$SOFA[i] <- ann$annot[annots_i]
    } else if(length(annots_i) > 1){
      snps$SOFA[i] <- paste(sort(unique(ann[annots_i,]$annot)), collapse = ":")
    } else {
      snps$SOFA[i] <- "NC"
    }
  }
  
# create "neutral" vcf
  
  col.vcf.nc <- col.vcf.good[which(snps$SOFA == "NC"), ]
  col.vcf.cd <- col.vcf.good[which(snps$SOFA != "NC"), ]
  
  write.vcf(col.vcf.nc, file = "~/Documents/Columbine/Data/GBS_Data/AQFO_snps_nc.vcf")
  write.vcf(col.vcf.cd, file = "~/Documents/Columbine/Data/GBS_Data/AQFO_snps_cd.vcf")
  
```


 
$~$

\subsubsection{References}









  
  
  